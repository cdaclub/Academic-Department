### 数值特征

#### 归一化（MinMax Scaling）

为什么要进行归一化？简单来说就是将数据缩放在[0,1]区间，防止量纲不一致。公式如下：
$$x_{\text{new}} = \frac{x - x_{\text{min}}}{x_{\text{max}} - x_{\text{min}}}$$
其中，$x$ 是原始数据，$x_{\text{new}}$ 是正则化后的数据，$x_{\text{min}}$ 和 $x_{\text{max}}$ 分别是数据的最小值和最大值。
代码如下：


```python
from sklearn import preprocessing
min_max_scaler= preprocessing.MinMaxScaler()
x = np.array([[ 1., -1.,  2.],
              [ 2.,  0.,  0.],
              [ 0.,  1., -1.]])
x_new = min_max_scaler.fit_transform(x)
x_new
```




    array([[0.5       , 0.        , 1.        ],
           [1.        , 0.5       , 0.33333333],
           [0.        , 1.        , 0.        ]])



使用sklearn.preprocessing.StandardScaler类也可以实现，使用该类的好处在于可以保存训练集中的参数（均值、方差）


```python
scaler = preprocessing.StandardScaler().fit(x)
scaler
```




    StandardScaler()




```python
scaler.mean_
```




    array([1.        , 0.        , 0.33333333])




```python
scaler.var_
```




    array([0.66666667, 0.66666667, 1.55555556])




```python
x_new = scaler.transform(x)   
x_new
```




    array([[ 0.        , -1.22474487,  1.33630621],
           [ 1.22474487,  0.        , -0.26726124],
           [-1.22474487,  1.22474487, -1.06904497]])



#### 标准化（Standardization）

为什么要进行标准化？数据经过零-均值标准化后均值为0，方差为1，更方便利于标准正态分布的性质。

将数据转换为均值为0，标准差为1的标准正态分布。

$$x_{\text{new}} = \frac{x - \mu}{\sigma} $$
使用sklearn.preprocessing.scale()函数，可以直接将给定数据进行标准化。代码如下：


```python
from sklearn import preprocessing
min_max_scaler= preprocessing.MinMaxScaler()
x = np.array([[ 1., -1.,  2.],
              [ 2.,  0.,  0.],
              [ 0.,  1., -1.]])
x_new = min_max_scaler.fit_transform(x)
x_new
```




    array([[0.5       , 0.        , 1.        ],
           [1.        , 0.5       , 0.33333333],
           [0.        , 1.        , 0.        ]])



使用sklearn.preprocessing.StandardScaler类也可以实现，使用该类的好处在于可以保存训练集中的参数（均值、方差）


```python
scaler = preprocessing.StandardScaler().fit(x)
scaler

scaler.mean_
scaler.var_
 
x_new = scaler.transform(x)   
x_new
```




    array([[ 0.        , -1.22474487,  1.33630621],
           [ 1.22474487,  0.        , -0.26726124],
           [-1.22474487,  1.22474487, -1.06904497]])



#### 正则化（Normalization）
为什么要进行正则化？正则化可以帮助防止过拟合，提高模型的泛化能力。

常见的正则化的方式有$l_1$正则化和$l_2$正则化

这里我们先看看$l_p$范数怎么计算？(这段如果理解不了，可以跳过，原理没有实践重要)

>
>p-范数的计算公式：
>$$ ||x||_p = \left( |x_1|^p + |x_2|^p + \ldots + |x_n|^p \right)^{\frac{1}{p}} $$
>
>其中，$x$是一个n维向量，$x_i$ 表示向量的第i个元素，$p$ 是范数的阶数。特别地，当$p=2$时，称为欧几里得范数（Euclidean norm）；当>$p=1$时，称为曼哈顿范数（Manhattan norm）。
>
>比如当我们有一个二维向量 $x = \begin{bmatrix} 3 \ 4 \end{bmatrix}$，我们可以计算不同p-范数的值。
>当 $p=1$ 时，曼哈顿范数（Manhattan norm）： 
>$$||x||_1 = |3| + |4| = 7$$
>当 $p=2$时，欧几里得范数（Euclidean norm）： 
>$$||x||_2 = \sqrt{3^2 + 4^2} = 5 $$
>
>有了范数，我们看看范数正则化的数学原理：
>
>给定一个矩阵 X，其中每一行表示一个样本，每一列表示一个特征。
>
>对于矩阵 X 中的每一行 x_i，L1 范数正则化的过程如下：
>
>1. 计算每一行的 L1 范数，即将该行中各个元素的绝对值相加。
>2. 将每个元素除以该行的 L1 范数，从而得到一个新的矩阵 x_new。
>
>具体来说，对于矩阵 X 中的第 i 行，L1 范数正则化的数学过程如下：
>$$ x_{\text{new},i} = \frac{x_{i}}{\sum_{j=1}^{n} |x_{ij}|} $$
>
>其中，$x_i$ 表示矩阵 $X$ 中的第 $i$ 行，$ x_{\text{new},i} $ 表示正则化后的第 i 行，n 表示矩阵 X 的列数。通过这个过程，矩阵 X 中的每一行都被重新缩放，使得每一行的元素之和为1，从而实现了 L1 范数正则化。
>

可以使用preprocessing.normalize()函数对指定数据进行转换，代码如下：


```python
x =  [[ 1., -1.,  2.],
      [ 2.,  0.,  0.],
      [ 0.,  1., -1.]]
x_new = preprocessing.normalize(x, norm='l1')
x_new
```




    array([[ 0.25, -0.25,  0.5 ],
           [ 1.  ,  0.  ,  0.  ],
           [ 0.  ,  0.5 , -0.5 ]])



也可以使用processing.Normalizer()类实现对训练集和测试集的拟合和转换，代码如下：


```python
x =  [[ 1., -1.,  2.],
      [ 2.,  0.,  0.],
      [ 0.,  1., -1.]]
x_new = preprocessing.normalize(x, norm='l2')
x_new
```




    array([[ 0.40824829, -0.40824829,  0.81649658],
           [ 1.        ,  0.        ,  0.        ],
           [ 0.        ,  0.70710678, -0.70710678]])



**统计值特征（max, min, mean, std）** 


```python
import pandas as pd
# 创建一个示例数据集
data = {
    'A': [1, 2, 3, 4, 5],
    'B': [10, 20, 30, 40, 50]
}
df = pd.DataFrame(data)
# 计算均值
mean_values = df['A'].mean()
# 计算标准差
std_values = df['A'].std()
# 计算最大值
max_values = df['A'].max()
# 计算最小值
min_values = df['A'].min()
```

**分箱离散化**


```python
import pandas as pd

# 创建一个示例数据集
data = {
    'age': [25, 30, 35, 40, 45, 50, 55, 60, 65, 70],
    'income': [35000, 50000, 65000, 80000, 95000, 110000, 125000, 140000, 155000, 170000]
}
df = pd.DataFrame(data)
# 定义分箱的边界
bins = [20, 30, 40, 50, 60, 70]
# 使用cut函数进行分箱离散化
df['age_bin'] = pd.cut(df['age'], bins)
# 打印结果
print(df['age_bin'])
```

    0    (20, 30]
    1    (20, 30]
    2    (30, 40]
    3    (30, 40]
    4    (40, 50]
    5    (40, 50]
    6    (50, 60]
    7    (50, 60]
    8    (60, 70]
    9    (60, 70]
    Name: age_bin, dtype: category
    Categories (5, interval[int64, right]): [(20, 30] < (30, 40] < (40, 50] < (50, 60] < (60, 70]]


**每个类别下对应的变量统计值histogram(分布状况)**


```python
import pandas as pd
# 创建一个示例数据集
data = {
    'category': ['A', 'B', 'A', 'B', 'A', 'B'],
    'value': [10, 20, 30, 40, 50, 60]
}
df = pd.DataFrame(data)
# 按照类别进行分组，然后计算每个类别下对应的变量的统计值
grouped = df.groupby('category')['value'].agg(['mean', 'median', 'std'])
grouped
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>median</th>
      <th>std</th>
    </tr>
    <tr>
      <th>category</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>A</th>
      <td>30.0</td>
      <td>30.0</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>B</th>
      <td>40.0</td>
      <td>40.0</td>
      <td>20.0</td>
    </tr>
  </tbody>
</table>
</div>



**数值型转化为类别型**


```python
import pandas as pd

# 创建一个示例数据集
data = {
    'age': [25, 30, 35, 40, 45, 50, 55, 60, 65, 70],
    'income': [35000, 50000, 65000, 80000, 95000, 110000, 125000, 140000, 155000, 170000]
}
df = pd.DataFrame(data)

# 将数值型变量进行分箱离散化
bins = [20, 30, 40, 50, 60, 70]
df['age_bin'] = pd.cut(df['age'], bins)

# 使用get_dummies函数生成哑变量
dummy_variables = pd.get_dummies(df['age_bin'], prefix='age_bin')
# 将生成的哑变量与原始数据集合并
df = pd.concat([df, dummy_variables], axis=1)
df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>income</th>
      <th>age_bin</th>
      <th>age_bin_(20, 30]</th>
      <th>age_bin_(30, 40]</th>
      <th>age_bin_(40, 50]</th>
      <th>age_bin_(50, 60]</th>
      <th>age_bin_(60, 70]</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>25</td>
      <td>35000</td>
      <td>(20, 30]</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>30</td>
      <td>50000</td>
      <td>(20, 30]</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>35</td>
      <td>65000</td>
      <td>(30, 40]</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>40</td>
      <td>80000</td>
      <td>(30, 40]</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>45</td>
      <td>95000</td>
      <td>(40, 50]</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>50</td>
      <td>110000</td>
      <td>(40, 50]</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>55</td>
      <td>125000</td>
      <td>(50, 60]</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>60</td>
      <td>140000</td>
      <td>(50, 60]</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>65</td>
      <td>155000</td>
      <td>(60, 70]</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>9</th>
      <td>70</td>
      <td>170000</td>
      <td>(60, 70]</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



### 类别特征

#### 序号编码（Ordinal Encoding）


```python
from sklearn.preprocessing import OrdinalEncoder

data = [['low'], ['medium'], ['high']]
encoder = OrdinalEncoder()
encoded_data = encoder.fit_transform(data)
print(encoded_data)
```

    [[1.]
     [2.]
     [0.]]


#### 独热编码（One-Hot Encoding）


```python
# 使用OneHotEncoder实现


import pandas as pd
from sklearn.preprocessing import OneHotEncoder

data = {'ID': [1, 2, 3],
        'Color': ['红色', '蓝色', '绿色']}
df = pd.DataFrame(data)
encoder = OneHotEncoder()
encoded_data = encoder.fit_transform(df[['Color']]).toarray()
df_encoded = pd.DataFrame(encoded_data, columns=encoder.get_feature_names(['Color']))
df = pd.concat([df, df_encoded], axis=1)
df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Color</th>
      <th>Color_红色</th>
      <th>Color_绿色</th>
      <th>Color_蓝色</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>红色</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>蓝色</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>绿色</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 使用OneHotEncoder实现

# 使用get_dummies实现
data = {'ID': [1, 2, 3],
        'Color': ['红色', '蓝色', '绿色']}
df = pd.DataFrame(data)
dummies = pd.get_dummies(df['Color'], prefix='Color')
df = pd.concat([df, dummies], axis=1)
df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Color</th>
      <th>Color_红色</th>
      <th>Color_绿色</th>
      <th>Color_蓝色</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>红色</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>蓝色</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>绿色</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_1 = pd.get_dummies(df['Color'], prefix='Color',drop_first=True)
df_1
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Color_绿色</th>
      <th>Color_蓝色</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



#### 二进制编码（Binary Encoding）


```python
from sklearn.preprocessing import LabelEncoder

data = [1,5,67,100]
encoder = LabelEncoder()
encoded_data = encoder.fit(data).transform([1,1,100,67,5])
print(encoded_data)
```

    [0 0 3 2 1]



```python
# import category_encoders as ce

# data = ['A', 'B', 'C']
# encoder = ce.BinaryEncoder(cols=['category'])
# encoded_data = encoder.fit_transform(data)
# print(encoded_data)
```

#### 标签编码（Label Encoding）


```python
from sklearn.preprocessing import LabelEncoder

data = ['cat', 'dog', 'rabbit']
encoder = LabelEncoder()
encoded_data = encoder.fit_transform(data)
print(encoded_data)

```

    [0 1 2]



```python
from sklearn.preprocessing import LabelEncoder

data = [1,5,67,100]
encoder = LabelEncoder()
encoded_data = encoder.fit(data).transform([1,1,100,67,5])
print(encoded_data)
```

    [0 0 3 2 1]


数值型特征工程小结：
- 连续型特征（Continuous Feature）：归一化（Min-Max Scaling）、零均值标准化（Z-Score Standardization）、L_p范数正则化（L_p Normalization）
- 离散型特征（Categorical Feature）：序号编码（Ordinal Encoding）、独热编码（One-hot Encoding）、 二进制编码（Binary Encoding）

